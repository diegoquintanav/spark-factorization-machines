{
 "metadata": {
  "name": "maquina_factorizacion_cerveza"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Checkeamos que el SparkContext este cargado correctamente"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print sc",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "<pyspark.context.SparkContext object at 0x2fa3c90>\n"
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "## Inicializacion\n\n**Observaci\u00f3n: A lo largo del notebook se le pide que asigne a algunas variables ciertos valores que son obtenidos en la ejecuci\u00f3n, tenga en cuenta que esto ser\u00e1 evaluado.**\n\nCargamos la librer\u00eda que implementa las m\u00e1quinas de factorizaci\u00f3n e importamos las distintas funciones."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "sc.addPyFile(\"./fm/fm_parallel_sgd.py\")\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import fm_parallel_sgd as fm\nfrom fm_parallel_sgd import *",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": "/usr/lib64/python2.6/site-packages/sklearn/utils/fixes.py:200: UserWarning: Using `sort` instead of partition.Upgrade numpy to 1.8 for better performace on large numberof clusters\n  warnings.warn('Using `sort` instead of partition.'\n"
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Seteamos algunos parametros de matplotlib para dibujar las figuras en el notebook:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import matplotlib.pylab as pylab\npylab.rcParams['figure.figsize']=(16.0, 12.0)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "## Cargamos el set de datos\n\nEl set de datos es un RDD (Resilient Distributed Dataset) de LabeledPoints donde las etiquetas deben tener el valor -1 o 1.\n\nLos vectores de caracter\u00edsticas deben ser un SparseVector o DenseVector de la librer\u00eda mllib.linalg.\n\nNuestro set de datos es de ratings de cervezas. Este set de datos posee los ratings por usuario y adem\u00e1s incluye el estilo de la cerveza evaluada."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "MLUtils.loadLibSVMFile??\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "nrPartitions = 5\ntrainPath = 'beer-dataset/beers_with_styles.train'\ntrainAll = MLUtils.loadLibSVMFile(sc, trainPath, numFeatures=10426).repartition(nrPartitions)\ntestPath = 'beer-dataset/beers_with_styles.test'\ntest = MLUtils.loadLibSVMFile(sc, testPath, numFeatures=10426)\n\nprint trainAll.count()\nprint test.count()\nprint trainAll.first??",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "44379\n2945"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n"
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print trainAll.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "(-1.0,(10426,[8,8332,10217],[1.0,1.0,1.0]))\n"
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.1: Explique en sus palabras qu\u00e9 significa esta salida: (-1.0,(10426,[8,8332,10217],[1.0,1.0,1.0]))**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Veamos cuanto tarda una iteraci\u00f3n de este algoritmo en correr, para que tengamos una noci\u00f3n del tiempo."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "temp = time.time()\nmodel = trainFM_parallel_sgd (sc, trainAll, iterations=1, iter_sgd=1, alpha=0.01, regParam=0.01, factorLength=4,\\\n                      verbose=False, savingFilename = None, evalTraining=None)\nprint 'time :'; print  time.time()-temp;",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "time :\n8.07438421249\n"
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Definimos una funci\u00f3n que nos ayude a interpretar las evaluaciones de un modelo."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def print_evaluate(test, model):\n    rtv_pr_auc, rtv_auc, logl, mse, acc =  evaluate(test, model)\n    print \"\u00c1rea bajo la curva del gr\u00e1fico Precision vs Recall: %.3f\" % rtv_pr_auc\n    print \"\u00c1rea bajo la ROC curva: %.3f\" % rtv_auc\n    print \"Log-perdida media: %.3f\" % logl\n    print \"MSE: %.3f\" % mse\n    print \"Exactitud (Accuracy): %.3f\" % acc",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.2: \u00bfCu\u00e1l es el tiempo de entrenamiento de cada iteraci\u00f3n?**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Entrenamiento de un modelo\n\nEntrenemos un modelo por 10 iteraciones utilizando m\u00e1quinas de factorizaci\u00f3n. \n\nEste modelo ser\u00e1 evaluado despu\u00e9s de cada iteraci\u00f3n utilizando validaci\u00f3n cruzada y ser\u00e1 guardado.\n\nPuedes ver los gr\u00e1ficos de las distintas m\u00e9tricas a lo largo del entrenamiento.\n\n**M\u00e9tricas:**\n\n\n**logl**: Log-perdida media\n\n**rtv_pr_auc**: \u00c1rea bajo la curva del gr\u00e1fico Precision vs Recall\n\n**rtv_auc**: \u00c1rea bajo la ROC curva\n\n**MSE**: Error cuadr\u00e1tico medio\n\n**Accuracy**: Exactitud"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "temp = time.time()\nevalTraining = evaluation(trainAll)\nevalTraining.modulo = 1\ntrainFM_parallel_sgd (sc, trainAll, iterations=10, iter_sgd= 3, alpha=0.01, regParam=0.01, factorLength=4,\\\n                      verbose=True, savingFilename = 'models/beers', evalTraining=evalTraining)\nprint 'Tiempo total: '; print  time.time()-temp;",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "iter \ttime \ttrain_logl \tval_logl\n0 \t0 \t0.693058 \t0.693056\n1 \t11 \t0.557078 \t0.558155"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n2 \t22 \t0.493423 \t0.493511"
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.3: \u00bfCu\u00e1l es el tiempo de entrenamiento y el resultado de las 4 distintas m\u00e9tricas para el modelo en la iteraci\u00f3n 10?** "
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.4: \u00bfSiempre se reduce el error en el set de entrenamiento entre dos iteraciones? \u00bfY en el de validaci\u00f3n? Explique.**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Podemos utilizar el modelo guardado con el mejor rendimiento en el set de validaci\u00f3n y lo utilzamos para ser evaluado con respecto al set de test. **Ojo:** Debes reemplazar **best_iter** con la iteraci\u00f3n en que se obtiene el mejor resultado en el set de validaci\u00f3n."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "best_iter = # Poner el mejor valor en el paso anterior\nmodel = loadModel('models/beers_iteration_%d' % best_iter)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print_evaluate(test, model)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.5: \u00bfCu\u00e1l es el rendimiento en el set de test? \u00bfPor qu\u00e9 se utiliza el test para medir el rendimiento?**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "## Exploraci\u00f3n de par\u00e1metros"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Ahora buscaremos hacer una sensibilidad con los distintos par\u00e1metros que tiene este algoritmo y as\u00ed ser capaces de encontrar un mejor modelo.\n\nPara hacer esta exploraci\u00f3n m\u00e1s r\u00e1pida, utilizaremos un subconjunto de los datos de entrenamiento un 10%."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "trainSample = trainAll.sample(False, 0.1)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "#### Tasa de Aprendizaje (alpha)\n\nVeamos como influye la tasa de aprendizaje en el rendimiento de este m\u00e9todo. Sientase en confianza de cambiar los valores en la variable **alpha_list** (agregar, quitar o modificar) a ver si encuentra uno mejor que el que se obtiene con los valores entregados."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "alpha_list = [0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1]\n\nmodel = plotAlpha(sc, trainSample, iterations=10, iter_sgd=1, alpha_list=alpha_list)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.6 Interprete con sus palabras que ocurre al aumentar el valor del par\u00e1metro alfa.**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "#### Dimensionalidad de los factores latentes (factorLength)\n\nVeamos como influye la dimensionalidad de los factores latentes en el rendimiento de este m\u00e9todo. Sientase en confianza de cambiar los valores en la variable **factorLength_list** (agregar, quitar o modificar) a ver si encuentra uno mejor que el que se obtiene con los valores entregados. "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "factorLength_list = [1, 5, 10, 15, 20, 30, 40]\n\nmodel = plotFactorLength(sc, trainSample, factorLength_list=factorLength_list,\\\n              iterations=5, iter_sgd=1, alpha=0.01, regParam=0.)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.7 Interprete con sus palabras que ocurre al aumentar el valor de la dimensionalidad de los factores.**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "#### Par\u00e1metro de Regularizaci\u00f3n (regParam)\n\nVeamos como influye el par\u00e1metro de regularizaci\u00f3n en el rendimiento de este m\u00e9todo. Sientase en confianza de cambiar los valores en la variable **regParam_list** (agregar, quitar o modificar) a ver si encuentra uno mejor que el que se obtiene con los valores entregados. "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regParam_list = [0, 0.0001, 0.001, 0.01, 0.1]\n\nmodel = plotRegParam(sc, trainSample, regParam_list=regParam_list, iterations=5, iter_sgd=1, alpha=0.01, factorLength=4)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.8 Interprete con sus palabras que ocurre al aumentar el valor del factor de regularizaci\u00f3n.**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "#### B\u00fasqueda en Grilla\n\nPor \u00faltimo, podemos buscar la mejor convinaci\u00f3n de par\u00e1metros (entre la tasa de aprendizaje y el par\u00e1metro de regularizaci\u00f3n) y as\u00ed obtener el mejor modelo posible. Sientase en confianza de cambiar los valores en las variables **alpha_list** y **regParam_list** (agregar, quitar o modificar) a ver si encuentra uno mejor que el que se obtiene con los valores entregados. \n"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "alpha_list = [0.01, 0.03, 0.06, 0.1]\nregParam_list = [0, 0.0001, 0.001, 0.01]\n\nbestModel = plotAlpha_RegParam(sc, trainSample, alpha_list=alpha_list,\\\n                       regParam_list=regParam_list, iterations=5, iter_sgd=10)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "## Utilizemos los mejores par\u00e1metros\n\nUsando los par\u00e1metros encontrados entrenemos un modelo tal y como lo hicimos al inicio. Reemplaza los mejores par\u00e1metros en las variables **best_alpha** y **best_regParam** a continuaci\u00f3n."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "best_alpha = # Rellenar con el mejor alfa obtenido en el paso anterior\nbest_regParam = # Rellenar con el mejor regParam obtenido en el paso anterior\n\ntemp = time.time()\nevalTraining = evaluation(trainAll)\nevalTraining.modulo = 2\ntrainFM_parallel_sgd (sc, trainAll, iterations=20, iter_sgd= 3, alpha=0.06, regParam=0.01, factorLength=4,\\\n                      verbose=True, savingFilename = 'models/beers_find', evalTraining=evalTraining)\nprint 'Tiempo total: '; print  time.time()-temp;",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Evaluemos este nuevo modelo. **Ojo:** Debes reemplazar **best_iter** con la iteraci\u00f3n en que se obtiene el mejor resultado en el set de validaci\u00f3n."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "best_iter = 20\nmodel = loadModel('models/beers_find_iteration_%d' % best_iter)\nprint_evaluate(test, model)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.9 De los todos par\u00e1metros que probo anteriormente \u00bfTodos influyen lo mismo? \u00bfCu\u00e1l es el que m\u00e1s influye?**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Utilicemos el modelo para hacer predicciones. Tomaremos las primeras 5."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "predictFM(test, model).take(5)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.10 \u00bfQu\u00e9 cree que significan estos valores y como los utilizar\u00eda para recomendar?**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**P2.11 Explique en sus palabras como replicar\u00eda este procedimiento para armar un modelo de recomendaci\u00f3n para libros.**"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "R:"
    }
   ],
   "metadata": {}
  }
 ]
}